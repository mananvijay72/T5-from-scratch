{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e86b7955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21563e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor:\n",
    "  \n",
    "  def __init__(self, data, _children=(), _op='', label=''):\n",
    "    self.data = data\n",
    "    self.grad = None\n",
    "    self._backward = lambda: None\n",
    "    self._prev = set(_children)\n",
    "    self._op = _op\n",
    "    self.label = label\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"Tensor(data={self.data})\"\n",
    "  \n",
    "  def __add__(self, other):\n",
    "    other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "    out = Tensor(self.data + other.data, (self, other), '+')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += 1.0 * out.grad\n",
    "      other.grad += 1.0 * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def __mul__(self, other):\n",
    "    other = other if isinstance(other, Tensor) else Tensor(other)\n",
    "    out = Tensor(self.data * other.data, (self, other), '*')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += other.data * out.grad\n",
    "      other.grad += self.data * out.grad\n",
    "    out._backward = _backward\n",
    "      \n",
    "    return out\n",
    "  \n",
    "  def __pow__(self, other):\n",
    "    assert isinstance(other, (int, float)), \"only supporting int/float powers for now\"\n",
    "    out = Tensor(self.data**other, (self,), f'**{other}')\n",
    "\n",
    "    def _backward():\n",
    "        self.grad += other * (self.data ** (other - 1)) * out.grad\n",
    "    out._backward = _backward\n",
    "\n",
    "    return out\n",
    "  \n",
    "  def __rmul__(self, other): # other * self\n",
    "    return self * other\n",
    "\n",
    "  def __truediv__(self, other): # self / other\n",
    "    return self * other**-1\n",
    "\n",
    "  def __neg__(self): # -self\n",
    "    return self * -1\n",
    "\n",
    "  def __sub__(self, other): # self - other\n",
    "    return self + (-other)\n",
    "\n",
    "  def __radd__(self, other): # other + self\n",
    "    return self + other\n",
    "\n",
    "  def tanh(self):\n",
    "    x = self.data\n",
    "    t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n",
    "    out = Tensor(t, (self, ), 'tanh')\n",
    "    \n",
    "    def _backward():\n",
    "      self.grad += (1 - t**2) * out.grad\n",
    "    out._backward = _backward\n",
    "    \n",
    "    return out\n",
    "  \n",
    "  def exp(self):\n",
    "    out = Tensor(np.exp(self.data), (self,), 'exp')\n",
    "\n",
    "    def _backward():\n",
    "      self.grad += out.data * out.grad \n",
    "    out._backward = _backward\n",
    "    return out\n",
    "  \n",
    "  def log(self):\n",
    "    out = Tensor(np.log(self.data), (self,), 'log')\n",
    "\n",
    "    def _backward():\n",
    "      self.grad += (1.0 / out.data) * out.grad\n",
    "    out._backward = _backward\n",
    "    return out\n",
    "  \n",
    "  \n",
    "  def backward(self):\n",
    "    \n",
    "    topo = []\n",
    "    visited = set()\n",
    "    def build_topo(v):\n",
    "      if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "          build_topo(child)\n",
    "        topo.append(v)\n",
    "    build_topo(self)\n",
    "    \n",
    "    self.grad = 1.0\n",
    "    for node in reversed(topo):\n",
    "      node._backward()\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c878c896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[6 3 0]\n",
       " [6 0 7]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Tensor(np.random.randint(0, 10, (2, 3)), label='x')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5e967d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manan\\AppData\\Local\\Temp\\ipykernel_34884\\2194371009.py:81: RuntimeWarning: divide by zero encountered in log\n",
      "  out = Tensor(np.log(self.data), (self,), 'log')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +=: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m b\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      5\u001b[0m c \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m+\u001b[39m x\n\u001b[1;32m----> 6\u001b[0m \u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m b\u001b[38;5;241m.\u001b[39mgrad, b\n",
      "Cell \u001b[1;32mIn[55], line 103\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(topo):\n\u001b[1;32m--> 103\u001b[0m   \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[55], line 19\u001b[0m, in \u001b[0;36mTensor.__add__.<locals>._backward\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_backward\u001b[39m():\n\u001b[1;32m---> 19\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m out\u001b[38;5;241m.\u001b[39mgrad\n\u001b[0;32m     20\u001b[0m   other\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m out\u001b[38;5;241m.\u001b[39mgrad\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +=: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "a = x.log()\n",
    "a.label = 'a'\n",
    "b = a.exp()\n",
    "b.label = 'b'\n",
    "c = a + x\n",
    "c.backward()\n",
    "b.grad, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a5ca613",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Tensor(2.0, label='a')\n",
    "b = Tensor(-3.0, label='b')\n",
    "c = Tensor(10.0, label='c')\n",
    "e = a*b; e.label = 'e'\n",
    "d = e + c; d.label = 'd'\n",
    "f = Tensor(-2.0, label='f')\n",
    "L = d * f; L.label = 'L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dd762ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d._op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "155a2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def trace(root):\n",
    "  # builds a set of all nodes and edges in a graph\n",
    "  nodes, edges = set(), set()\n",
    "  def build(v):\n",
    "    if v not in nodes:\n",
    "      nodes.add(v)\n",
    "      for child in v._prev:\n",
    "        edges.add((child, v))\n",
    "        build(child)\n",
    "  build(root)\n",
    "  return nodes, edges\n",
    "\n",
    "def draw_dot(root):\n",
    "  dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'}) # LR = left to right\n",
    "  \n",
    "  nodes, edges = trace(root)\n",
    "  for n in nodes:\n",
    "    uid = str(id(n))\n",
    "    # for any Tensor in the graph, create a rectangular ('record') node for it\n",
    "    dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad), shape='record')\n",
    "    if n._op:\n",
    "      # if this Tensor is a result of some operation, create an op node for it\n",
    "      dot.node(name = uid + n._op, label = n._op)\n",
    "      # and connect this node to it\n",
    "      dot.edge(uid + n._op, uid)\n",
    "\n",
    "  for n1, n2 in edges:\n",
    "    # connect n1 to the op node of n2\n",
    "    dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "\n",
    "  return dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01701c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.1.1 (20250719.2154)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"1140pt\" height=\"154pt\"\n",
       " viewBox=\"0.00 0.00 1140.00 154.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 150)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-150 1135.75,-150 1135.75,4 -4,4\"/>\n",
       "<!-- 2408426038336 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>2408426038336</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"315.38,-27.5 315.38,-63.5 502.88,-63.5 502.88,-27.5 315.38,-27.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"326.38\" y=\"-40.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">e</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"337.38,-28 337.38,-63.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"379.5\" y=\"-40.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;6.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"421.62,-28 421.62,-63.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"462.25\" y=\"-40.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2408426043712+ -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>2408426043712+</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"567\" cy=\"-72.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"567\" y=\"-67.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2408426038336&#45;&gt;2408426043712+ -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>2408426038336&#45;&gt;2408426043712+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M503.05,-61.6C512.25,-63.19 521.16,-64.73 529.24,-66.13\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"528.48,-69.55 538.93,-67.81 529.68,-62.66 528.48,-69.55\"/>\n",
       "</g>\n",
       "<!-- 2408426038336* -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2408426038336*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"251.25\" cy=\"-45.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"251.25\" y=\"-40.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2408426038336*&#45;&gt;2408426038336 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>2408426038336*&#45;&gt;2408426038336</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M278.69,-45.5C286.1,-45.5 294.64,-45.5 303.71,-45.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"303.51,-49 313.51,-45.5 303.51,-42 303.51,-49\"/>\n",
       "</g>\n",
       "<!-- 2408426036896 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2408426036896</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"314.25,-82.5 314.25,-118.5 504,-118.5 504,-82.5 314.25,-82.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"325.25\" y=\"-95.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">c</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"336.25,-83 336.25,-118.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"379.5\" y=\"-95.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 10.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"422.75,-83 422.75,-118.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"463.38\" y=\"-95.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2408426036896&#45;&gt;2408426043712+ -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2408426036896&#45;&gt;2408426043712+</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M504.39,-83.57C513.16,-81.99 521.65,-80.47 529.37,-79.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"529.73,-82.57 538.95,-77.36 528.49,-75.68 529.73,-82.57\"/>\n",
       "</g>\n",
       "<!-- 2408426043568 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2408426043568</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"630,-109.5 630,-145.5 816,-145.5 816,-109.5 630,-109.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"640.25\" y=\"-122.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">f</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"650.5,-110 650.5,-145.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"692.62\" y=\"-122.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;2.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"734.75,-110 734.75,-145.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"775.38\" y=\"-122.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2408426040064* -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>2408426040064*</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"879\" cy=\"-99.5\" rx=\"27\" ry=\"18\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"879\" y=\"-94.45\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">*</text>\n",
       "</g>\n",
       "<!-- 2408426043568&#45;&gt;2408426040064* -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>2408426043568&#45;&gt;2408426040064*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M816.25,-110.73C825.1,-109.12 833.67,-107.56 841.46,-106.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"841.93,-109.62 851.15,-104.38 840.68,-102.73 841.93,-109.62\"/>\n",
       "</g>\n",
       "<!-- 2408426040064 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2408426040064</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"942,-81.5 942,-117.5 1131.75,-117.5 1131.75,-81.5 942,-81.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"954.12\" y=\"-94.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">L</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"966.25,-82 966.25,-117.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1008.38\" y=\"-94.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;8.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"1050.5,-82 1050.5,-117.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"1091.12\" y=\"-94.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2408426040064*&#45;&gt;2408426040064 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2408426040064*&#45;&gt;2408426040064</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M906.44,-99.5C913.59,-99.5 921.78,-99.5 930.49,-99.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"930.26,-103 940.26,-99.5 930.26,-96 930.26,-103\"/>\n",
       "</g>\n",
       "<!-- 2408426043712 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>2408426043712</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"631.12,-54.5 631.12,-90.5 814.88,-90.5 814.88,-54.5 631.12,-54.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"642.5\" y=\"-67.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">d</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"653.88,-55 653.88,-90.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"693.75\" y=\"-67.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 4.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"733.62,-55 733.62,-90.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"774.25\" y=\"-67.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2408426043712&#45;&gt;2408426040064* -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2408426043712&#45;&gt;2408426040064*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M815.36,-88.52C824.5,-90.12 833.36,-91.67 841.4,-93.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"840.58,-96.49 851.04,-94.77 841.79,-89.6 840.58,-96.49\"/>\n",
       "</g>\n",
       "<!-- 2408426043712+&#45;&gt;2408426043712 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2408426043712+&#45;&gt;2408426043712</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M594.47,-72.5C601.87,-72.5 610.38,-72.5 619.43,-72.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"619.17,-76 629.17,-72.5 619.17,-69 619.17,-76\"/>\n",
       "</g>\n",
       "<!-- 2408426034544 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>2408426034544</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-55.5 0,-91.5 188.25,-91.5 188.25,-55.5 0,-55.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"11.38\" y=\"-68.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">b</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"22.75,-56 22.75,-91.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"64.88\" y=\"-68.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data &#45;3.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"107,-56 107,-91.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"147.62\" y=\"-68.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2408426034544&#45;&gt;2408426038336* -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2408426034544&#45;&gt;2408426038336*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M188.49,-56.65C197.36,-55.05 205.93,-53.5 213.73,-52.09\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"214.2,-55.56 223.42,-50.34 212.95,-48.68 214.2,-55.56\"/>\n",
       "</g>\n",
       "<!-- 2408426042800 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>2408426042800</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"2.62,-0.5 2.62,-36.5 185.62,-36.5 185.62,-0.5 2.62,-0.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"13.62\" y=\"-13.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">a</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"24.62,-1 24.62,-36.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"64.5\" y=\"-13.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">data 2.0000</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"104.38,-1 104.38,-36.5\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"145\" y=\"-13.7\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">grad 0.0000</text>\n",
       "</g>\n",
       "<!-- 2408426042800&#45;&gt;2408426038336* -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2408426042800&#45;&gt;2408426038336*</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M185.81,-34.28C195.45,-35.96 204.82,-37.59 213.29,-39.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"212.65,-42.51 223.1,-40.77 213.85,-35.61 212.65,-42.51\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x230c198dba0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_dot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131ee7c6",
   "metadata": {},
   "source": [
    "# Manual back propgation\n",
    "\n",
    "gradiant at current point of L with respect to each variable (which will be weigght in NN)\n",
    "\n",
    "for calculation can use limit format == f(x+h) - f(x) / h    h---> 0 this will be the rate of change at that point of x or differentiation\n",
    "\n",
    "1. dL/dd = d(d*f)/dd = f\n",
    "2. dL/df = d(d*f)/df = d\n",
    "\n",
    "## Chain rule\n",
    "since now they are not directly connected to L we will use chain rule\n",
    "\n",
    "3. dL/dc = dL/dd * dd/dc  = f * d(e+c)/de = f*1\n",
    "4. dL/de = dL/dd * dd/de  = f * d(e+c)/de = f*1\n",
    "\n",
    "5. dL/da = dL/de * de/da = f * d(a*b)/da = f*b\n",
    "6. dL/db = dL/de * de/db = f * d(a*b)/da = f*a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.grad = f.data\n",
    "f.grad = d.data\n",
    "e.grad = d.grad * 1\n",
    "c.grad = d.grad * 1 \n",
    "a.grad = e.grad * b.data\n",
    "b.grad = e.grad * a.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de91b122",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a69fcce",
   "metadata": {},
   "source": [
    "# Nueral network implementaion manual\n",
    "\n",
    "single neuron with two input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefe5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input Tensors\n",
    "x1 = Tensor(2.0, label='x1')\n",
    "x2 = Tensor(3.0, label='x2')\n",
    "\n",
    "#weights\n",
    "w1 = Tensor(4.0, label='w1')\n",
    "w2 = Tensor(-5.0, label='w2')\n",
    "\n",
    "#bias\n",
    "b = Tensor(6.0, label='b')\n",
    "\n",
    "#output\n",
    "x1w1 = x1 * w1; x1w1.label = 'x1w1'\n",
    "x2w2 = x2 * w2; x2w2.label = 'x2w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1 + x2w2'\n",
    "z = x1w1x2w2 + b; z.label = 'z'\n",
    "y = z.tanh(); y.label = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc632ce",
   "metadata": {},
   "source": [
    "# Manual back propogation for neuron\n",
    "rate of change pf y with respect to other variables "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd54065",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff263c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad = 1.0\n",
    "z.grad = 1 - y.data**2  #diff of tanh dy/dz = 1-(tanh z)^2 = 1 - y^2\n",
    "b.grad = z.grad * 1\n",
    "x1w1x2w2.grad = z.grad * 1  #plus operation same as derivative of parent\n",
    "x1w1.grad = x1w1x2w2.grad \n",
    "x2w2.grad = x1w1x2w2.grad #plus operation same as derivative of parent\n",
    "x1.grad = x1w1.grad * w1.data\n",
    "x2.grad = x2w2.grad * w2.data\n",
    "w1.grad = x1w1.grad * x1.data\n",
    "w2.grad = x2w2.grad * x2.data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400cc607",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b44f1d",
   "metadata": {},
   "source": [
    "# Back propgation automatic\n",
    "\n",
    "now since we know how the gradient flows with respect to each operation +,*,tanh we can find the grad from the Tensor of self and grad of its parent\n",
    "\n",
    "we will define self._backwar = lambda: None #a funcntion which does nothing by default\n",
    "\n",
    "we will create and set this function to object in each operation __add__, __mul__ etc\n",
    "\n",
    "set up in the Tensor class\n",
    "rec create the NN and verify the auto grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ef646",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85798d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input Tensors\n",
    "x1 = Tensor(2.0, label='x1')\n",
    "x2 = Tensor(3.0, label='x2')\n",
    "\n",
    "#weights\n",
    "w1 = Tensor(4.0, label='w1')\n",
    "w2 = Tensor(-5.0, label='w2')\n",
    "\n",
    "#bias\n",
    "b = Tensor(6.0, label='b')\n",
    "\n",
    "#output\n",
    "x1w1 = x1 * w1; x1w1.label = 'x1w1'\n",
    "x2w2 = x2 * w2; x2w2.label = 'x2w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1 + x2w2'\n",
    "z = x1w1x2w2 + b; z.label = 'z'\n",
    "y = z.tanh(); y.label = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fb436",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff341da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.grad = 1.0 # for the final output, we set the gradient to 1.0\n",
    "y._backward()\n",
    "z._backward()\n",
    "b._backward()\n",
    "x1w1x2w2._backward()\n",
    "x1w1._backward()\n",
    "x2w2._backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759f671",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bf65e7",
   "metadata": {},
   "source": [
    "#### In case a single chile have multiple parent then in that case if we set grad as '=' then it will over write the gradinet we ewant to accumulate it so we will use +="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba8a5e",
   "metadata": {},
   "source": [
    "# Topology\n",
    "\n",
    "the order of calling the backpropogation matters, last Tensor should be called first for gradient then its childs in order . To do that we use topological sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959a8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = []\n",
    "visited = set()\n",
    "\n",
    "def build_topo(v):\n",
    "    if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "            build_topo(child)\n",
    "        \n",
    "        topo.append(v)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_topo(y)\n",
    "topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089e53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the final element in topo is the output, so we can call its backward function to start the backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1324c16",
   "metadata": {},
   "source": [
    "# autpgrad using topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN\n",
    "#input Tensors\n",
    "x1 = Tensor(2.0, label='x1')\n",
    "x2 = Tensor(3.0, label='x2')\n",
    "\n",
    "#weights\n",
    "w1 = Tensor(4.0, label='w1')\n",
    "w2 = Tensor(-5.0, label='w2')\n",
    "\n",
    "#bias\n",
    "b = Tensor(6.0, label='b')\n",
    "\n",
    "#output\n",
    "x1w1 = x1 * w1; x1w1.label = 'x1w1'\n",
    "x2w2 = x2 * w2; x2w2.label = 'x2w2'\n",
    "x1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1w1 + x2w2'\n",
    "z = x1w1x2w2 + b; z.label = 'z'\n",
    "y = z.tanh(); y.label = 'y'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af64a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()  # start the backpropagation from the output Tensor\n",
    "draw_dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ada9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_topo(y)\n",
    "y.grad = 1.0  # for the final output, we set the gradient to 1.0\n",
    "for v in reversed(topo):\n",
    "    v._backward()  # call the backward function of each Tensor in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96777e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa91d85",
   "metadata": {},
   "source": [
    "Now we can incorporate this in our class "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544259c4",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d614a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "\n",
    "    def __init__(self,n_input):\n",
    "        self.W = [Tensor(np.random.uniform(-1,1)) for _ in range(n_input)]\n",
    "        self.b = Tensor(np.random.uniform(-1,1))\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        assert len(x) == len(self.W), \"Input size must match number of weights\"\n",
    "        #z = w.x +b\n",
    "        act = self.b\n",
    "        for wi, xi in zip(self.W, x):\n",
    "            act = act + (wi * xi)\n",
    "        out = act.tanh()  # apply activation function\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return self.W + [self.b]\n",
    "    \n",
    "class Layer:\n",
    "\n",
    "    def __init__(self, n_input, n_neurons):\n",
    "        self.neurons = [Neuron(n_input) for _ in range(n_neurons)]\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        assert len(x) == len(self.neurons[0].W), \"Input size must match number of weights\"\n",
    "        out = [n(x) for n in self.neurons]\n",
    "        return out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [param for neuron in self.neurons for param in neuron.parameters()]\n",
    "    \n",
    "class MLP:\n",
    "\n",
    "    def __init__(self, n_input, layer_sizes : list):\n",
    "        self.layers = []\n",
    "        input = n_input\n",
    "        for layer_size in layer_sizes:\n",
    "            self.layers.append(Layer(input, layer_size))\n",
    "            input = layer_size\n",
    "\n",
    "    def __call__(self, x):\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [param for layer in self.layers for param in layer.parameters()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa2f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [Tensor(2.0), Tensor(3.0)]\n",
    "n = Neuron(2)\n",
    "n(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f483e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = Layer(2, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f5b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "l(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(2, layer_sizes=[2, 3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a4e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf229285",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_dot(mlp(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928e9e97",
   "metadata": {},
   "source": [
    "# Example NN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2976262",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [[Tensor(2.0), Tensor(3.0), Tensor(-1.0)],\n",
    "      [Tensor(3.0), Tensor(-1.0), Tensor(0.5)],\n",
    "      [Tensor(0.5), Tensor(1.0), Tensor(1.0)],\n",
    "      [Tensor(1.0), Tensor(1.0), Tensor(-1.0)]]\n",
    "\n",
    "ys = [[Tensor(1.0)],\n",
    "      [Tensor(-1.0)],\n",
    "        [Tensor(-1.0)],\n",
    "        [Tensor(1.0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55f9205",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(3, layer_sizes=[2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = [mlp(x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f139a137",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2468c111",
   "metadata": {},
   "source": [
    "# Implementing the loss function, optimizers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333257c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSE\n",
    "\n",
    "loss = sum([(ygt[0]-yout[0])**2 for ygt,yout in zip(ys, ypred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573fcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac21ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0430201",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.layers[0].neurons[0].W[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e01363",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.layers[0].neurons[0].parameters() #w ==3 w + 1 b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e850d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a766292",
   "metadata": {},
   "source": [
    "### now we have individual parameters and their individua; gradients.\n",
    "Now we can start optimizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf4970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "#parameter to monitor \n",
    "mlp.layers[0].neurons[0].W[0].data, mlp.layers[0].neurons[0].W[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a146a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in mlp.parameters():\n",
    "    p.data -= learning_rate * p.grad  # simple gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.layers[0].neurons[0].W[0].data, mlp.layers[0].neurons[0].W[0].grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289c4dfa",
   "metadata": {},
   "source": [
    "reduced by a tiny amount as grad was positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d92899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new preds and loss\n",
    "ypred = [mlp(x) for x in xs]\n",
    "loss = sum([(ygt[0]-yout[0])**2 for ygt,yout in zip(ys, ypred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f0d862",
   "metadata": {},
   "source": [
    "loss reduced , so optimization successfull repeating this process will become training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce524c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "\n",
    "    #forward pass\n",
    "    ypred = [mlp(x) for x in xs]\n",
    "    loss = sum([(ygt[0]-yout[0])**2 for ygt,yout in zip(ys, ypred)])\n",
    "\n",
    "    \n",
    "    #backward pass\n",
    "    for p in mlp.parameters():\n",
    "        p.grad = 0.0 # reset gradients before backpropagation\n",
    "    loss.backward()\n",
    "    \n",
    "    #gradient descent step\n",
    "    for p in mlp.parameters():\n",
    "        p.data -= learning_rate * p.grad  # simple gradient descent step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc4963",
   "metadata": {},
   "source": [
    "This prediction is very close to the target :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d6e7bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ae422d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
